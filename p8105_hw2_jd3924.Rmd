---
title: "p8105_hw2_jd3924"
author: "Jiahe Deng"
date: "2022-10-01"
output: github_document
---

```{r}
library(tidyr)
library(readxl)
library(tidyverse)
library(readr)
```

### Problem 1
Below we import and clean data from `NYC_Transit_Subway_Entrance_And_Exit_Data.csv`. The process begins with data import, updates variable names, and selects the columns that will be used in later parts fo this problem. We update `entry` from `yes` / `no` to a logical variable. As part of data import, we specify that `Route` columns 8-11 should be character for consistency with 1-7.

```{r}
trans_ent = 
  read_csv("NYC_Transit_Subway_Entrance_And_Exit_Data.csv",
           col_types = cols(Route8 = "c", Route9 = "c",
                            Route10 = "c", Route11 = "c")) %>% 
  janitor::clean_names() %>% 
  select(
    line, station_name, station_latitude, station_longitude, 
    starts_with("route"), entry, exit_only, vending, entrance_type, 
    ada) %>% 
  mutate(entry = ifelse(entry == "YES", TRUE, FALSE))
```

As it stands, these data are not "tidy": route number should be a variable, as should route. That is, to obtain a tidy dataset we would need to convert `route` variables from wide to long format. This will be useful when focusing on specific routes, but may not be necessary when considering questions that focus on station-level variables. 

The following code chunk selects station name and line, and then uses `distinct()` to obtain all unique combinations. As a result, the number of rows in this dataset is the number of unique stations.

```{r}
trans_ent %>% 
  select(station_name, line) %>% 
  distinct
```

The next code chunk is similar, but filters according to ADA compliance as an initial step. This produces a dataframe in which the number of rows is the number of ADA compliant stations. 

```{r}
trans_ent %>% 
  filter(ada == TRUE) %>% 
  select(station_name, line) %>% 
  distinct
```

To compute the proportion of station entrances / exits without vending allow entrance, we first exclude station entrances that do not allow vending. Then, we focus on the `entry` variable -- this logical, so taking the mean will produce the desired proportion (recall that R will coerce logical to numeric in cases like this).

```{r}
trans_ent %>% 
  filter(vending == "NO") %>% 
  pull(entry) %>% 
  mean
```

Lastly, we write a code chunk to identify stations that serve the A train, and to assess how many of these are ADA compliant. As a first step, we tidy the data as alluded to previously; that is, we convert `route` from wide to long format. After this step, we can use tools from previous parts of the question (filtering to focus on the A train, and on ADA compliance; selecting and using `distinct` to obtain dataframes with the required stations in rows).

```{r}
trans_ent %>% 
  pivot_longer(
    route1:route11,
    names_to = "route_num",
    values_to = "route") %>% 
  filter(route == "A") %>% 
  select(station_name, line) %>% 
  distinct

trans_ent %>% 
  pivot_longer(
    route1:route11,
    names_to = "route_num",
    values_to = "route") %>% 
  filter(route == "A", ada == TRUE) %>% 
  select(station_name, line) %>% 
  distinct
```

### Problem 2
```{r}
mr_trash_wheel = 
  read_excel("Trash Wheel Collection Data.xlsx", range=cell_cols("A:N")) %>%
  janitor::clean_names() %>% 
  drop_na(dumpster) %>%
  mutate(sports_balls = as.integer(sports_balls),
         year = as.integer(year))
mr_trash_wheel
```
```{r}
mr_trash_wheel %>%
  filter(year== "2020") %>%
  select(sports_balls) %>%
  colSums()
```

In mr_trash_wheel dataset, there are 547 observation and 14 variables.
the total number of sports balls collected by Mr. Trash Wheel in 2020
is `r mr_trash_wheel %>%
  filter(year== "2020") %>%
  select(sports_balls) %>%
  colSums()`
The data arrange accourding to date.




```{r}
pro_trash_wheel = 
  read_excel("Trash Wheel Collection Data.xlsx",sheet = 2) %>%
  janitor::clean_names() %>%
  drop_na(dumpster) %>%
  mutate(year=as.integer(year))
pro_trash_wheel
```
```{r}
pro_trash_wheel %>%
  select(weight_tons) %>%
  colSums()
```

In Pro_trash_Wheel, there are 822 observation and 9 variable. the total weight of trash collected by Professor Trash Wheel is `r pro_trash_wheel %>%
  select(weight_tons) %>%
  colSums()` tons.
```{r}
mr_trash_wheel %>%
  mutate(source = 'mr_trash_wheel')

pro_trash_wheel %>%
  mutate(source = 'pro_trash_wheel')

new_data = bind_rows(mr_trash_wheel,pro_trash_wheel)
new_data


```
### Problem 3
```{r}
pols_month = 
  read_csv("fivethirtyeight_datasets/pols-month.csv") %>%
  janitor::clean_names() %>%
  separate(col = mon,into = c("year","month","day"),sep = '-', convert = TRUE) %>%
  mutate(
    month=month.abb[.$month],
    president = ifelse(prez_dem,"dem","gop"),
    month= str_to_upper(month)) %>%
  select(-day,-prez_gop,-prez_dem)
pols_month
```
```{r}
snp =
  read_csv("fivethirtyeight_datasets/snp.csv") %>%
  janitor::clean_names() %>%
  separate(col = date,into = c("month","day","year"),sep = '/', convert = TRUE) %>%
  mutate(year=ifelse(year<23, year+2000, year+1900),
         month=month.abb[.$month],
         year=as.integer(year),
         month= str_to_upper(month)) %>%
  select(year,month,close,-day) %>%
  arrange(year,month) 
snp
```
```{r}
unemployment= 
  read_csv("fivethirtyeight_datasets/unemployment.csv") %>%
  janitor::clean_names() %>% 
  pivot_longer(jan:dec, names_to = "month",values_to = "unemployment") %>%
  drop_na(unemployment) %>%
  mutate(month= str_to_upper(month),
         year=as.integer(year))
unemployment
```
```{r}
pol_and_snp = left_join(pols_month,snp, by=c("year","month"))
left_join(pol_and_snp,unemployment, by=c("year","month"))
```
For problem3, clean the data in pols-month.csv. 
In this dataset, there are 822 observation,and 9 variables. 
It contains the information about the national politicians 
who are democratic or republican from 1947 to 2015. 
I combine the pre_gop and prez_dem into one column called president. 
Which is more clear and tidy. 

For snp dataset, it is about the closing values of the S&P stock index from 1950 to 2015
I separate the date in to month and year.And I modify the year into 4 digit, and delet the day.
Which enbales snp can join with other datasets later.

For unemployment dataset, it is about the unemployment rate from 1948 to 2015.
I arrange the data by month. Also, I drop the NA.
It is because this dataset is about unemployment.
if the row have no information about unemployment
I think it is better to drop it. 

After combine these three date, we can see the information about the national politicians, S&P stock index, and unemployment for particular date at the same time. 